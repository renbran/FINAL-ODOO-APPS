<?xml version="1.0" encoding="utf-8"?>
<odoo>
    <data noupdate="1">
        <!-- Example LLM Providers (inactive by default) -->

        <!-- OpenAI GPT-4 -->
        <record id="llm_provider_openai_gpt4" model="llm.provider">
            <field name="name">OpenAI GPT-4</field>
            <field name="sequence">10</field>
            <field name="provider_type">openai</field>
            <field name="model_name">gpt-4-turbo-preview</field>
            <field name="api_key">your-openai-api-key-here</field>
            <field name="temperature">0.7</field>
            <field name="max_tokens">2000</field>
            <field name="timeout">30</field>
            <field name="active" eval="False"/>
            <field name="is_default" eval="False"/>
        </record>

        <!-- Groq Llama 3.3 (Latest - Recommended FREE option) -->
        <record id="llm_provider_groq_llama" model="llm.provider">
            <field name="name">Groq Llama 3.3 70B (Free)</field>
            <field name="sequence">20</field>
            <field name="provider_type">groq</field>
            <field name="model_name">llama-3.3-70b-versatile</field>
            <field name="api_key">your-groq-api-key-here</field>
            <field name="temperature">0.7</field>
            <field name="max_tokens">2000</field>
            <field name="timeout">30</field>
            <field name="active" eval="False"/>
            <field name="is_default" eval="False"/>
        </record>

        <!-- Anthropic Claude -->
        <record id="llm_provider_anthropic_claude" model="llm.provider">
            <field name="name">Anthropic Claude 3 Sonnet</field>
            <field name="sequence">30</field>
            <field name="provider_type">anthropic</field>
            <field name="model_name">claude-3-sonnet-20240229</field>
            <field name="api_key">your-anthropic-api-key-here</field>
            <field name="temperature">0.7</field>
            <field name="max_tokens">2000</field>
            <field name="timeout">30</field>
            <field name="active" eval="False"/>
            <field name="is_default" eval="False"/>
        </record>

        <!-- Google Gemini -->
        <record id="llm_provider_google_gemini" model="llm.provider">
            <field name="name">Google Gemini Pro</field>
            <field name="sequence">40</field>
            <field name="provider_type">google</field>
            <field name="model_name">gemini-pro</field>
            <field name="api_key">your-google-api-key-here</field>
            <field name="temperature">0.7</field>
            <field name="max_tokens">2000</field>
            <field name="timeout">30</field>
            <field name="active" eval="False"/>
            <field name="is_default" eval="False"/>
        </record>

        <!-- HuggingFace -->
        <record id="llm_provider_huggingface" model="llm.provider">
            <field name="name">HuggingFace Mixtral</field>
            <field name="sequence">50</field>
            <field name="provider_type">huggingface</field>
            <field name="model_name">mistralai/Mixtral-8x7B-Instruct-v0.1</field>
            <field name="api_key">your-huggingface-token-here</field>
            <field name="temperature">0.7</field>
            <field name="max_tokens">2000</field>
            <field name="timeout">60</field>
            <field name="active" eval="False"/>
            <field name="is_default" eval="False"/>
        </record>

        <!-- Mistral AI -->
        <record id="llm_provider_mistral" model="llm.provider">
            <field name="name">Mistral AI Large</field>
            <field name="sequence">60</field>
            <field name="provider_type">mistral</field>
            <field name="model_name">mistral-large-latest</field>
            <field name="api_key">your-mistral-api-key-here</field>
            <field name="temperature">0.7</field>
            <field name="max_tokens">2000</field>
            <field name="timeout">30</field>
            <field name="active" eval="False"/>
            <field name="is_default" eval="False"/>
        </record>
    </data>
</odoo>
